{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architectures classiques d'Autoencoders\n",
    "## Débruitage et classification automatique d'images + génération de données\n",
    "disclaimer: exemples récupérés du tutoriel officiel Keras\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "Article de review principalement utilisé: <br\\>\n",
    "Charte and al. A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines, Information Fusion journal, 2018 \n",
    "\n",
    "lien arxiv pour dl: https://arxiv.org/abs/1801.01586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "pylab.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère le fameux dataset MNIST de chiffres manuscrits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple d'image qui se trouve dans le dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb2b031c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(1, 1))\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On normalise le tout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:100, :]\n",
    "x_test = x_test[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction des AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bdacore.neural_networks.keras_factory import SimpleAutoEncoderFactory, DeepAutoEncoderFactory, \\\n",
    "AutoEncoderClassifier, CNNDenoisingAutoEncoder2DFactory, VariationalAutoEncoderFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans BDAcore, la classe KerasFactory renvoie habituellement un seul modèle de réseaux de neurones, qu'on passe ensuite en argument d'un wrapper Keras Scikit. Dans le cas des AutoEncoders, on peut avoir besoin d'avoir accès à la couche \"centrale\", de manière à capturer la représentation \"compressée\" de la donnée. Pour cela, toutes les factories d'AutoEncoders de BDAcore renvoie le modèle global avec au moins l'encodeur, voire le décodeur dans certains cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![autoencoder](https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rester \"skitlearn compliant\", Keras possède un wrapper scikit. Pour rester compatible avec le contrat scikit, étant donné qu'on a besoin d'au moins 2 modèles en même temps (autoencoder + encoder), une classe AutoEncoderClassifier a été créée de manière à avoir un wrapper \"skitlearn compliant\" encapsulant les 2 modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# petite fonction basée sur le code du tuto pour l'affichage\n",
    "def plot_images(x_test, decoded_imgs, x_test_reshape_size=(28,28) , decoded_imgs_reshape_size=(28,28), n=10):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(x_test_reshape_size))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(decoded_imgs_reshape_size))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La taille de la donnée d'entrée correspond à une image à plat (28 x 28 = 784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = x_train.shape[1]\n",
    "image_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_factory = SimpleAutoEncoderFactory()\n",
    "autoencoder, encoder, _ = ae_factory.create_model(encoding_dim=32, input_size=image_size)\n",
    "clf_keras = AutoEncoderClassifier(autoencoder, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture en 3 couches classique d'un autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 10 samples\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6951 - val_loss: 0.6937\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.6943 - val_loss: 0.6930\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.6935 - val_loss: 0.6923\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 109us/step - loss: 0.6927 - val_loss: 0.6917\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.6920 - val_loss: 0.6910\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.6912 - val_loss: 0.6904\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 112us/step - loss: 0.6905 - val_loss: 0.6897\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.6898 - val_loss: 0.6891\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 101us/step - loss: 0.6890 - val_loss: 0.6884\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.6883 - val_loss: 0.6876\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.6874 - val_loss: 0.6868\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.6865 - val_loss: 0.6860\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.6856 - val_loss: 0.6850\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 74us/step - loss: 0.6845 - val_loss: 0.6840\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.6834 - val_loss: 0.6829\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.6821 - val_loss: 0.6816\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.6807 - val_loss: 0.6803\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.6791 - val_loss: 0.6788\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.6774 - val_loss: 0.6771\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.6754 - val_loss: 0.6752\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.6733 - val_loss: 0.6731\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 55us/step - loss: 0.6708 - val_loss: 0.6707\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.6681 - val_loss: 0.6681\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.6651 - val_loss: 0.6651\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.6617 - val_loss: 0.6618\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 67us/step - loss: 0.6580 - val_loss: 0.6582\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 57us/step - loss: 0.6538 - val_loss: 0.6541\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.6492 - val_loss: 0.6496\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.6441 - val_loss: 0.6447\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 63us/step - loss: 0.6386 - val_loss: 0.6392\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.6324 - val_loss: 0.6333\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.6257 - val_loss: 0.6268\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.6184 - val_loss: 0.6198\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.6105 - val_loss: 0.6122\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 53us/step - loss: 0.6019 - val_loss: 0.6041\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.5928 - val_loss: 0.5954\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.5831 - val_loss: 0.5861\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.5728 - val_loss: 0.5764\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.5619 - val_loss: 0.5661\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.5506 - val_loss: 0.5555\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.5389 - val_loss: 0.5445\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.5268 - val_loss: 0.5332\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 68us/step - loss: 0.5144 - val_loss: 0.5218\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 61us/step - loss: 0.5019 - val_loss: 0.5102\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.4893 - val_loss: 0.4986\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.4768 - val_loss: 0.4870\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.4644 - val_loss: 0.4757\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.4522 - val_loss: 0.4645\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.4404 - val_loss: 0.4537\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.4290 - val_loss: 0.4432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd36761810>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_keras.fit(x_train, x_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=256,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux valeurs de loss tournent autour de 0.102, 0.104 (pour info, c'est de la binary crossentropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = clf_keras.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(x_test, decoded_imgs, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient ici une représention reconstruite du jeu de test, où l'autoencoder simple (3 couches) s'est contenté d'essayer de reconstruire l'image d'origine avec comme contrainte la couche du milieu qui compresse l'ensemble de la donnée. On peut l'utiliser pour du débruitage ou de la détection d'outliers (ce qui n'est pas ressorti de l'autre côté est soit considéré comme du bruit, soit comme une anomalie au choix), même si la partie débruitage n'est pas forcément extraordinaire dans ce cas précis, vu la simplicité de l'architecture de l'AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(x_test, clf_keras.encoded_data_, decoded_imgs_reshape_size=(8,4), n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il sera intéressant de jeter un oeil à la partie compressée de l'image (couche du milieu) car celle-ci équivaut à effectuer une réduction de dimensions. Dans le cas d'un AE simple, cela revient à effectuer une PCA. Cela fera l'objet d'une application spécifique avec un autre type d'autoencoders qui permet des réductions de dimensions non-linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_factory = DeepAutoEncoderFactory()\n",
    "autoencoder, encoder = ae_factory.create_model(input_size=image_size, start_layer_size=256, sub_layers_level=4)\n",
    "clf_keras = AutoEncoderClassifier(autoencoder, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture en sablier, où l'on donne la taille de départ, et le nombre de sous-couches intermédiaires (taille divisée par 2 à chaque fois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_keras.fit(x_train, x_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=256,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = clf_keras.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_images(x_test, decoded_imgs, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même si la loss est quasi identique, on a l'impression que l'AE peine à reconstruire l'image. En fonction des applications, cela peut être voulu, de sorte que plus de bruit sera filtré par exemple. Dans le cas des chiffres manuscrits, le delta entre la sortie et l'entrée pourrait servir à estimer la lisibilité du caractère par un humain (plus le delta est grand, moins le chiffre est lisible à l'origine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on repasse en 2 dimensions, on recharge les données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:100, :]\n",
    "x_test = x_test[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_factory = CNNDenoisingAutoEncoder2DFactory()\n",
    "autoencoder, encoder = ae_factory.create_model(shape=(28, 28, 1))\n",
    "clf_keras = AutoEncoderClassifier(autoencoder, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succession de couches de convolution et de max pooling, et même chose dans l'autre sens, avec des couches upsampling à la place des max pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé des images bruitées, et on créé une relation entre l'image originale et sa version bruitée en prenant comme entréee l'image bruitée et en cible l'image non bruitée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAADuCAYAAADyW8OMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAD5JJREFUeJztnXmMVcUSxmtgREUYBpQBQX3IuAAiroALahQVMBIjEnGPQjAqKi5BExSNGnAZQEWQGBcUoog7i1FwQVFHUTaXoOAKgktYZV+d98fjlV8VnMO9d2Zwpvh+f1Wn7j3nDB+n+1Z3dXVeWVmZkLjU+LcfgFQuFDg4FDg4FDg4FDg4FDg4FDg4FDg4FDg4+dl8OC8vz0x77bHHHmpv3rw54+sUFBSovWrVqsTP1a5d27Rr1Pjn/+Pee+9tfEuWLFF7r732Mr4DDjhA7R9++CHj5/Qcd9xxas+cOTOnazRp0sS0f/vtt1wfZ2lZWVnDnX0oK4E9RUVFai9evDjj75188slqv/XWW4mfa9GihWnjf4yWLVsa38iRI9Vu3ry58T344INqd+3aNePn9MyYMUPtvLy8nK5x7bXXmvaAAQNyfZwFmXyIXXRwKHBw8rJZTfJjMDJmzBjTvvPOO9Vu1aqV8aV1y/369VO7pKQk42dDcKwUEdl///3VnjRpUk7XFBHp0KGD2h9//LHxdenSRe3PP//c+JYtW5Z4zaOPPlrtOXPmJH7uvvvuM+0BAwbMLCsrOz79ifkGh4cCB6dcv6KRyy+/3LQPOeQQtdO6ZM8vv/yi9lVXXWV8s2fPVtuHQp999pnavos+5phj1K5Tp47xbdmyxbRfeeUVtTG8EhG54YYb1PZddNrf2LlzZ7VLS0uN78ILL0x8lm+++Ubttm3bJl4/Db7BwaHAwaHAwckqTMrPzy+rV6+etpcvX5742fHjx6u9detW4+vWrZvaL774ovFddNFFag8dOtT4brnlFrX9zFnTpk0TnwX/Rj8D5b+XzYwcMm7cOLV79OhhfJMnT1YbZ8NERO64447Ea+KM3yeffOLdDJMIBQ5PuWayiouL1f7xxx/NZ7F7ue6664zv0ksvVbtTp07Gh92ZD4XOPPNMtTdu3Gh877zzTuJzDx48WO1nn33W+DAUERG599571fYLAdi9N2rUyPj+/PPPxPtnCoZMIiIvvfRS2sfZRRMKHB4KHJyspirr169vxkwf4iD4sz5tBccv6uMYvGHDBuObO3eu2jgV6pk/f75pn3322WovXbo08XsiInfddZfab7zxhvGtWLFC7RNPPNH4Fiz4Z/29fv36xrdu3Tq1fZiWFsIlfW5nn0X4BgeHAgcnqy569erV8v7772d9E99lYV7So48+mvF1TjnlFLV9uHPwwQerff/99xvfzz//nPE9kL59+5r2r7/+qjbOXPk2dskiIh999FHiPTLtanPNAeMbHBwKHBwKHJwKS7rziejr16/P6Jr5+fZnAGY1+Gf7+uuv1T7yyCMzur7nyy+/NG0fNr366qtqP/7444nX8b8rMCnf52VjhskTTzyReM3XX3/dtM8///zEzwqnKokIBQ5PVl10nTp1ylq3bq1tXP3AlR4Ru1jvV5qmT5+u9rBhw4zv008/Vfu5557L+NmQIUOGmDaGYgsXLjQ+H25deeWVidfFUMV/D2ey7r77buMbNGiQ2n/88Yfx+b8/iYYN7TakJUuWsIsmFDg8FDg4WU1VFhUVyY033qhtzMzw4JZNn8iGe4lvv/1248ME8kceecT4brrpJrXfe+894+vYsaPat956q/Fh22eQTJkyJfEeaVtN9913X9PGvdIeDP2+++67xOuk7WHyv3HGjh2b+FmEb3BwKHBwyjWThft81qxZYz577LHHqj1r1izjw64P9w2JiLz22mtq4wqRiE0c8M89evRotTF3W8Qu4vuZrDT8jFStWrXU9l0tPo/vvtPyx5G//vrLtHG4wnzxbTBMIhQ4PBQ4OFmHSRgaPfPMM2r7kAnDqYceesj4cMVm4sSJiffzSeknnHCC2rgfWOR/2Sb/xyelY2kEnxnhSzXhOPvTTz8ZX2FhYeKzpmVcYMkl3BAgYhML/W8H/++WC3yDg0OBg1OuMAm3XvrZKlyV8SsvabRr105tnwyAXfaBBx5ofBgK+fIKuGKzs+S1yy67TG1fvQ+3fvoVMpxZ6tOnj/FhmIRVdUTs8HH66acb39SpU9MelWESocDhocDBySpMqlGjhtmzi+OuL0/kpyeRPffc858HcOMsZnv4MRD3LfmVHpw69BVlMTNkZ785evbsqTbuhRLZPrEQufjiixPvgb8BfEYJVtv1Y+4999yjNv7GEOHeJLINChycrLromjVrmpUSXG3xs05fffWV2lhxR0TkvPPOU9uXYrjkkkvUznRRW8RW8vFV53DBvX379sbnF+pxP9JRRx1lfGndIhYjxWpAIrbLHjFihPE1btxYbV9V6LbbblP7ySefTLx3GnyDg0OBg0OBg1OuqUoMDXxIg1OJfg8whlp+L21F4DMxMIvD7zfyCXo1a9ZMvO4111yjts++wHIWOyjerbbfb4QZLB4MPdeuXevdnKokFDg8FDg45ar4jodtzJs3z/gefvhhtX3sh8tpZ511lvF98cUXaq9cuTLx3v78IZz+xHuL2MrtvvyR36+Lsaif8vz777/V9hXucQxu0KCB8eG4jweEiOReeyNT+AYHhwIHp8JKOPTq1cu0n376abWvvvpq48PKc/7gDUye89x8881qT5gwwfh8hgWCyXK+22/WrJlp46EgWf7bqO0P88DQy09/4t/hK+v56rPIpk2bGCYRChweChycrMKkwsJCk/mHZX9waUvEjsHHH2+Hiu7duyfeAzM1fFI8jl+bNm0yPgx3hg8fbnwDBw5MvCaeRyiy/fiJYH0S3OwmYg/Neuyxx4wPM0p8dV0cg3EjgYjdL1y3bt3E50qDb3BwKHBwsuqii4uLzeoHhgaHH3544vd8KIQHaLz88svG9/vvvydeB5PpfXkHXKXBVR+R9HDHhyZYlQ6PyBWxWSvffvut8WG3/O677xofDhGY+eHxe5P8UJMLfIODQ4GDQ4GDk9VUZa1atcqKioq0nXbOH1ZjLSgoMD7MesRkdhG7f9YfjIUrVn4aD8sX4pSmiB3L/GrOBRdcsOM/QEQWLVpk2pil4o9xx01zPlMTsyxxb7TI9itWWcCpSkKBw5NVmLR58+aMj1/F8gN+jw8mCnhKSkrU7tevn/Fht+yT9bAgt+e0005T2xcS95VhsaxTWkFuP7TgHmhfsRar/vlKuJj058s77OBI2azhGxwcChwcChycCsvoSANDCBEbYvgENaxn4cfA77//Xm08oGPbs6mNdS9E7CoUJuuL2AwOke3LMyF4XuJ+++2X+D2f6I8b2nx1W/yt4sMyXy7RwTCJUODwlKuLxhIDfo9NWlXX0tJStX2e8gsvvKC2Xxxv2bKl2r6cwlNPPaV27969E+/t/15/TC0mNOA1ywNWz/OJCpkeL+sTERYtWsQumlDg8FDg4FRYmNS5c2fTfvvtt9Xu0aOH8bVp00btgw46yPiwlKA/iAKzPXyYMm3atMTnRnyC/KGHHmrauLrkS0ONGjVKbZ8gh9XpfUnCK664Qm2frId7rEaOHGl8uCrl918LwyQiQoHDU64uGvf1+BkhXG3xZxUhPskOu8H+/fsbHx4vf8YZZ+z8gXcAdpci2y/c4+zRqaeeanyZDgMeTEj0K2TPP/+82mnVZQ877DDTnj9/PrtoQoHDQ4GDU64xGBPacez0+IRuX4IoU0466SS1cbrTg6UWROw5h74Kri/h4A/iSMInsGMioR+rmzRporafGsUxOO0syB3AMZhQ4PBklXRXr149k8CG3XLagRJYCdbjE9TSDvDACrYePOzCV6s755xz1H7zzTeNz1fk8TnVSWCVWBE7A+dnyzDc8qEQ/rsVFxcbH17HVyPC/V1p8A0ODgUODgUOTrZh0hIRWVB5j0Oy4D9lZWUNd/ahrAQm1Q920cGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMGhwMHJKm021zpZpFJYmknKDt/g6ktGuXEUODgUODgUODgUODgUODgUODgUODgUODgUODgUODgUODgUODgUODgUODgUODgUODhZZXRUF3whNF8rM43rr79e7dq1axsf1n3u06eP8Q0ePFhtf7rahg0b1H7ggQeMD48mqgz4BgeHAgenSnfR/kQWPEEMSwuLiHTo0EHtwsJC48OTVMoDHh45bNgw48ODNFevXm18eArchx9+WCHPkil8g4NDgYNDgYOzSw6Izgas+4zH6IhkF+5UBP5ogJ49e6q9Zs2axO/5o4JWrFih9rx58yro6VjSnwgFDk+VC5MWLlyo9rJly4yvIrro6dOnm/bKlStNG0vs+8Ocx4wZU+7772r4BgeHAgeHAgenyo3By5cvV9uf1HnuueeqPXv2bOPzU4fInDlz1PbH06xdu9a0jzjiCLX79u2bwRNXbfgGB4cCB6fKzWSlUVBQoLZfscFDJnv16mV8eCrZ2LFjK+npdjmcySIUODwUODhVLkxKY9WqVYm+tEOne/furfa4ceOMz68YRYNvcHAocHCqVZiUxj777KP2xIkTjQ8Pte7SpYvxTZkypXIfrPJgmEQocHgocHDCjMFIcXGxac+aNUttn8ExdepU054xY4baI0aMML4qdtYyx2BCgcMTsov24L6hUaNGGV/dunUTv9e/f3/THj16tNo+9/lfgF00ocDhocDB2S3GYKR169amPXToUNPu2LFj4ncxa2TgwIHGt3jx4gp4uqzgGEwocHgocHB2uzHY4+t5dO3aVW0fM+fl5ant9y77hPpdAMdgQoHDs9t30Wls3LjRtPPz/8lR3LJli/F16tRJ7Q8++KBSn2sb7KIJBQ4PBQ5OtUp8rwjatGlj2t27dzfttm3bqo1jrmfu3LmmPW3atAp4uoqHb3BwKHBwQnbRWLhbxBb57tatm/E1btw44+tu3bpVbZ/RUVX3OPENDg4FDg4FDk61HYP92IkHYeCYKyLSrFmznO6BSfAiNotjwoQJOV1zV8M3ODgUODhVuotu1KiRabdq1Urt4cOHG1+LFi1yuoevPltSUqL2+PHjja+qhkJp8A0ODgUODgUOzr8+Bjdo0MC0MbkcD+gQEWnevHlO9ygtLVV7yJAhxjd58mTTXr9+fU73qKrwDQ4OBQ7OLumi27dvb9pY6Ltdu3bG17Rp05zusW7dOrV9cfBBgwap7QuAR4dvcHAocHAocHB2yRiMNTJ21E7CJ7ZNmjRJbZ94juGPL5W0O8M3ODgUODjcm1R94d4kQoHDQ4GDQ4GDQ4GDQ4GDQ4GDQ4GDQ4GDQ4GDk+1q0lIRWVAZD0Ky5j+ZfCiruWhS/WAXHRwKHBwKHBwKHBwKHBwKHBwKHBwKHBwKHJz/Ajb4fWkh1/p+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(x_train_noisy, x_train, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On donne à l'autoencoder l'image bruitée en entrée avec pour cible l'image non-bruitée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.7390 - val_loss: 0.6763\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6766 - val_loss: 0.6278\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.5670\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5718 - val_loss: 0.4983\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.4704\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.4672\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.4587\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.4545\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.4469\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.4417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2adedbd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_keras.fit(x_train_noisy, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde ensuite ce que cela donne si on donne à l'AE des images bruitées jamais rencontrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = clf_keras.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(x_test_noisy, decoded_imgs, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont plutôt bons dans l'ensemble et l'AE fait le job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On recharge les données proprement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "image_size = x_train.shape[1]\n",
    "original_dim = image_size * image_size\n",
    "x_train = np.reshape(x_train, [-1, original_dim])\n",
    "x_test = np.reshape(x_test, [-1, original_dim])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:100, :]\n",
    "x_test = x_test[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_factory = VariationalAutoEncoderFactory()\n",
    "autoencoder, encoder, decoder = ae_factory.create_model(input_size=784, intermediate_dim=256, latent_dim=16, epsilon_std=1.0)\n",
    "clf_keras = AutoEncoderClassifier(autoencoder, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce type d'AE utiliser une approche bayésienne variationnelle pour l'encodage. On suppose qu'il existe une variable aléatoire latente non observée $y$ qui, par un processus aléatoire, conduit aux observations $x$. Son objectif est donc d'approximer la distribution de la variable latente à partir des observations. Les AE variationnels remplacent les fonctions déterministes dans l'encodeur et le décodeur par des applications stochastiques, et calculent la fonction objectif selon les fonctions de densité des variables aléatoires de la distribution estimée (ici on utilise la loi normale).\n",
    "\n",
    "Comme ces modèles appartiennent à la catégorie des réseaux de neurones génératifs, ils permettent également de créer de nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 10 samples\n",
      "Epoch 1/15\n",
      "100/100 [==============================] - 0s 118us/step - loss: 295.7971 - val_loss: 294.8884\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 0s 163us/step - loss: 283.3232 - val_loss: 281.2496\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 0s 191us/step - loss: 270.3691 - val_loss: 284.6578\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 0s 101us/step - loss: 264.8552 - val_loss: 267.3797\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 0s 102us/step - loss: 256.9158 - val_loss: 258.4368\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 0s 97us/step - loss: 250.7155 - val_loss: 264.4670\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 0s 209us/step - loss: 248.0166 - val_loss: 260.5433\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 0s 214us/step - loss: 239.6353 - val_loss: 252.8483\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 0s 125us/step - loss: 238.4431 - val_loss: 237.2575\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 0s 124us/step - loss: 233.1709 - val_loss: 235.8755\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 0s 128us/step - loss: 234.0320 - val_loss: 233.0684\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 0s 138us/step - loss: 228.7633 - val_loss: 237.9156\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 0s 119us/step - loss: 226.5711 - val_loss: 231.4576\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 0s 180us/step - loss: 224.2125 - val_loss: 234.3477\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 0s 131us/step - loss: 224.2487 - val_loss: 228.7911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2ab34290>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_keras.fit(x_train, None,\n",
    "                        epochs=15,\n",
    "                        batch_size=128,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering automatique d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend le jeu de test et on le transforme en sa représentation \"compressée\" à 16 dimensions. L'objectif est ensuite d'y appliquer un algorithme de réduction de dimension non-linéaire type manifold. Dans ce cas de figure, l'AE permet de réduire la dimension car les algorithmes type manifold ne sont pas faits pour traiter de très grandes dimensions. Ici, on passe de 784 dimensions à 16 dimensions, qu'on va réduire à 2 dimensions, ce qui permettra d'afficher et de faire du clustering classique. On pourrait réduire grâce à l'AE directement à 2 dimensions, mais les résultats sont bien moins bons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient bien nos 10 000 images de test dans une représentation à 16 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 16)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_encoded[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit un dataframe qu'on va utiliser avec une réduction de dimensions type manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(x_test_encoded[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.110014</td>\n",
       "      <td>0.924425</td>\n",
       "      <td>0.796352</td>\n",
       "      <td>1.077659</td>\n",
       "      <td>-0.116121</td>\n",
       "      <td>-2.138069</td>\n",
       "      <td>-1.360329</td>\n",
       "      <td>-0.121193</td>\n",
       "      <td>2.507831</td>\n",
       "      <td>-0.651001</td>\n",
       "      <td>-0.704277</td>\n",
       "      <td>-0.895097</td>\n",
       "      <td>-0.989126</td>\n",
       "      <td>0.700750</td>\n",
       "      <td>-1.834688</td>\n",
       "      <td>0.274764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.798244</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>1.682636</td>\n",
       "      <td>2.187859</td>\n",
       "      <td>1.281359</td>\n",
       "      <td>0.953046</td>\n",
       "      <td>-2.925138</td>\n",
       "      <td>0.958744</td>\n",
       "      <td>3.020417</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>-0.109269</td>\n",
       "      <td>1.323348</td>\n",
       "      <td>-1.455718</td>\n",
       "      <td>1.670491</td>\n",
       "      <td>0.313840</td>\n",
       "      <td>-0.304688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.574769</td>\n",
       "      <td>0.374225</td>\n",
       "      <td>1.751449</td>\n",
       "      <td>2.343125</td>\n",
       "      <td>1.460200</td>\n",
       "      <td>0.836329</td>\n",
       "      <td>-2.190854</td>\n",
       "      <td>-1.459035</td>\n",
       "      <td>2.881112</td>\n",
       "      <td>-0.485541</td>\n",
       "      <td>-2.434419</td>\n",
       "      <td>0.987045</td>\n",
       "      <td>-0.387929</td>\n",
       "      <td>3.319902</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>-1.333738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.757737</td>\n",
       "      <td>3.535808</td>\n",
       "      <td>3.175558</td>\n",
       "      <td>1.558805</td>\n",
       "      <td>1.297816</td>\n",
       "      <td>-1.376057</td>\n",
       "      <td>-2.920655</td>\n",
       "      <td>-0.007543</td>\n",
       "      <td>0.755235</td>\n",
       "      <td>-1.080010</td>\n",
       "      <td>-1.872491</td>\n",
       "      <td>0.913250</td>\n",
       "      <td>-1.335097</td>\n",
       "      <td>1.723480</td>\n",
       "      <td>-0.646683</td>\n",
       "      <td>-0.939129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287599</td>\n",
       "      <td>-0.068053</td>\n",
       "      <td>0.895389</td>\n",
       "      <td>1.017585</td>\n",
       "      <td>1.384775</td>\n",
       "      <td>0.819595</td>\n",
       "      <td>-1.263190</td>\n",
       "      <td>-0.622105</td>\n",
       "      <td>1.857936</td>\n",
       "      <td>0.366440</td>\n",
       "      <td>0.207119</td>\n",
       "      <td>-0.579625</td>\n",
       "      <td>-1.286241</td>\n",
       "      <td>0.771950</td>\n",
       "      <td>-0.240163</td>\n",
       "      <td>-0.245597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.110014  0.924425  0.796352  1.077659 -0.116121 -2.138069 -1.360329   \n",
       "1  1.798244  0.013318  1.682636  2.187859  1.281359  0.953046 -2.925138   \n",
       "2  0.574769  0.374225  1.751449  2.343125  1.460200  0.836329 -2.190854   \n",
       "3  1.757737  3.535808  3.175558  1.558805  1.297816 -1.376057 -2.920655   \n",
       "4  0.287599 -0.068053  0.895389  1.017585  1.384775  0.819595 -1.263190   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.121193  2.507831 -0.651001 -0.704277 -0.895097 -0.989126  0.700750   \n",
       "1  0.958744  3.020417  0.001254 -0.109269  1.323348 -1.455718  1.670491   \n",
       "2 -1.459035  2.881112 -0.485541 -2.434419  0.987045 -0.387929  3.319902   \n",
       "3 -0.007543  0.755235 -1.080010 -1.872491  0.913250 -1.335097  1.723480   \n",
       "4 -0.622105  1.857936  0.366440  0.207119 -0.579625 -1.286241  0.771950   \n",
       "\n",
       "         14        15  \n",
       "0 -1.834688  0.274764  \n",
       "1  0.313840 -0.304688  \n",
       "2  0.966981 -1.333738  \n",
       "3 -0.646683 -0.939129  \n",
       "4 -0.240163 -0.245597  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 2.45 ms, total: 108 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_man = TSNE()\n",
    "test_reduc = clf_man.fit_transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On est en mesure d'afficher les images dans un espace à 2 dimensions, et à l'oeil, on se rend compte qu'avec un processus complétement automatique, on s'en sort plutôt bien. Même si t-SNE est à la base fait pour de la visualisation, il permet également de bien séparer les différentes images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finaliser l'approche, on applique sur cet espace à 2 dimensions un algorithme de clustering permettant de spécifier le nombre de classes (ici 10), et on mesure ensuite avec la V-Mesure le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_clust = AgglomerativeClustering(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = clf_clust.fit_predict(test_reduc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999999, 0.8193820026016113, 0.9007256325828685)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homogeneity_completeness_v_measure(labels_true=y_test[:10],labels_pred=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La V-Mesure obtient environ 84%, on arrive donc à capturer 84% de l'information (de l'entropie) de manière juste, et de manière automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Génération d'images\n",
    "La particularité des modèles variationels d'AE est qu'ils appartiennent à la catégorie des réseaux de neurones génératifs. On peut donc s'amuser à générer des données à envoyer à la couche du milieu, demander à la partie décodeur de sortir un résultat et de voir ce que cela donne.\n",
    "\n",
    "Pour générer les données, il faut donc fournir des tableaux de dimension 16. On choisit la distribution normale pour tirer aléatoirement des valeurs puisque c'est cette dernière qui est estimée par l'AE a priori (approche bayésienne). Pour l'exemple, on génère 15 lignes de 16 valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_sample = np.random.normal(size=(15,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_decoded = decoder.predict(z_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche la représention compressée de taille 16 générée aléatoirement, et le résultat obtenu en-dessous par le décodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(z_sample, x_decoded , x_test_reshape_size=(4,4), n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parfois les images générées ne font pas sens, mais on est tout de même en mesure de créer des images de chiffres manuscrits qui ne ressemblent à aucun de ceux présents dans le dataset d'origine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Debrief:\n",
    "Un gros pavé que ce tutoriel sur les autoencoders, et un grand nombre de papiers existent avec des usages assez surprenants. Dans notre quotidien, l'approche non-supervisée de classification d'image (ou autre source de données) peut être certainement utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdacore",
   "language": "python",
   "name": "bdacore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
